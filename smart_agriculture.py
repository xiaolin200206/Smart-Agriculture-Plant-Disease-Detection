# -*- coding: utf-8 -*-
"""Smart agriculture.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AXcQ7SgoDwcpBuJDz0AlWLWP94ZbXnId
"""

#Calculate the mean and std
import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import os

data_dir = "/kaggle/input/plantvillage-dataset/plantvillage dataset/color" # Corrected path
simple_transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor()
])

dataset = datasets.ImageFolder(root=data_dir, transform=simple_transform) # Changed variable name from datasets to dataset
dataloader = DataLoader(dataset=dataset, batch_size=32, shuffle=False, num_workers=2) # Changed variable name from DataLoader to dataloader, set shuffle to False for consistent mean/std calculation


mean = 0.0
std = 0.0
total_images = 0

for images, _ in dataloader: # Changed variable name from image to images
    batch_samples = images.size(0) # Changed variable name from batch_sample to batch_samples and from img to images
    images = images.view(batch_samples, images.size(1), -1) # Reshape images to (batch_size, channels, height * width)
    mean += images.mean(2).sum(0) # Calculate mean over height*width and sum over batch
    std += images.std(2).sum(0) # Calculate std over height*width and sum over batch
    total_images += batch_samples # Accumulate total number of images

mean /= total_images
std /= total_images

print(f"Mean: {mean}")
print(f"Std: {std}")

"""Download dataset and list all data path"""

import kagglehub
from pathlib import Path
# Download latest version
path = Path(kagglehub.dataset_download("abdallahalidev/plantvillage-dataset"))
print("Path to dataset files:", path)
#get all .jpg file recursivel
all_images = list(path.rglob("*.jpg"))

print("Total image files:", len(all_images))
print("sample files:/n", all_images[:10])

"""Import library"""

import pandas as np
import numpy as np
import matplotlib.pyplot as plt
import torch
import torchvision
from torchvision import transforms, datasets
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

"""Check vision"""

print(torch.__version__)
print(torchvision.__version__)

"""Get data *list* and path"""

import random
from PIL import Image

#set seed
#random.seed(44)

#1.get all image pathj
all_image = list(path.glob("*/*/*.jpg"))
#pick a random image path
random_image_path = random.choice(all_images)
#get image class from path name(the image class is the name of the directory where the image is stored)
all_image = random_image_path.parent.stem
#open image
img = Image.open(random_image_path)
img

"""try to visualize! visualize! visualize"""

#turn the image into array
img_as_array = np.array(img)
#plot the image
plt.figure(figsize=(12,6))
plt.imshow(img_as_array)
plt.xlabel(all_image)
plt.title("image after transform")
plt.axis(False)

"""Now transform data"""

image_data_train_transform = transforms.Compose([
    #resize our image to 255,255
    transforms.Resize(size=(224,224)),
    transforms.RandomHorizontalFlip(p=0.05),
    transforms.RandomRotation(degrees=10),
    transforms.RandomAffine(degrees=0, translate=(0.1,0.1), scale=(0.9,1.1)),
    #turn the data into a torch.tensor
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.4667, 0.4894, 0.4106],
                         std=[0.1697, 0.1425, 0.1867])
])
image_data_test_transform = transforms.Compose([
    transforms.Resize(size=(224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.4667, 0.4894, 0.4106],
                         std=[0.1697, 0.1425, 0.1867])
])

#plot what we transform data
mean = torch.tensor([0.4667, 0.4894, 0.4106])
std = torch.tensor([0.1697, 0.1425, 0.1867])

def unnormalize(img_tensor, mean, std):
  img_tensor = img_tensor.clone() #make the copy so we don't modify the original
  for t, m, s in zip(img_tensor, mean, std): # t mean channel, m mean mean value, s mean standard deviation
    t.mul_(s).add_(m) #this means t = t * std + mean
  return img_tensor

#apply transform
img_data_after_transform = image_data_train_transform(img)

#unnormalize for visualization
img_data_unnorm = unnormalize(img_data_after_transform, mean, std)

#convert to numpy and plot
img_data_after_transform_array = img_data_unnorm.permute(1,2,0).numpy().clip(0,1) #permute(1,2,0) mean change shape from [3,H,W] - > [H,W,3]
#clip mean ensure values stay in the valid range for display(0,1)
plt.figure(figsize=(12,6))
plt.imshow(img_data_after_transform_array)
plt.title("image after transform")
plt.axis(False)
plt.show()

import random
from PIL import Image

def plot_transformed_image(image_paths, transforms, n=3, seed=None):
  """
  Selects random images from a list of image paths and loads/transforms
  them, then plots the original vs the transformed version.
  """
  if seed:
    random.seed(seed)
  random_image_paths = random.sample(image_paths, k=n) # Renamed for clarity
  for image_path in random_image_paths: # Iterate directly over the random paths
    with Image.open(image_path) as F:
      fig, ax = plt.subplots(nrows=1, ncols=2)
      ax[0].imshow(F)
      ax[0].set_title(f"original\nsize:{F.size}")
      #transform and plot target image
      transform_image = transforms(F) # applu the transformation
      transform_image = transform_image.permute(1,2,0).numpy()# we will need to change shape for matplotlib(C,H,W) -> (H,W,C)

      #unnormallize the image
      mean = torch.tensor([0.4667, 0.4894, 0.4106])
      std = torch.tensor([0.1697, 0.1425, 0.1867])
      transform_image = transform_image * std.numpy() + mean.numpy()
      transform_image = np.clip(transform_image, 0,1)
      ax[1].imshow(transform_image)
      ax[1].set_title(f"transformed\nsize:{transform_image.shape}") # Added a title for the transformed image
      ax[1].axis("off")
      fig.suptitle(f"class:{image_path.parent.stem}", fontsize=16) # Changed subtitle to suptitle and fixed variable name
      plt.show() # Added plt.show() to display the plot

# Corrected the function call with the correct arguments
plot_transformed_image(image_paths=all_images,
                       transforms=image_data_train_transform,
                       n=3,
                       seed=42)

"""Loading image data with imagefolder"""

train_data = datasets.ImageFolder(root=path / "plantvillage dataset" / "color", # Corrected path
                   transform = image_data_train_transform,
                   target_transform=None)
test_data = datasets.ImageFolder(root=path / "plantvillage dataset" / "color", # Corrected path
                   transform = image_data_train_transform) # Assuming test data also uses train transform for consistency

"""  Get class name as list"""

class_names = train_data.classes
class_names

"""Get class name as dict"""

class_names = train_data.class_to_idx
class_names

"""Check the length of dataset"""

len(train_data), len(test_data)

"""Index on the train_data dataset to get a single image and label"""

img, label = train_data[0][0], test_data[0][1]
print(f"image tensor:\n {img}")
print(f"image shape: {img.shape}")
print(f"image datatype: {img.dtype}")
print(f"image label: {label}")
print(f"label datatype: {type(label)}")

mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]

# Unnormalize the image tensor
img_un = unnormalize(img, mean, std)

# Rearrange dimensions
img_un = img_un.permute(1, 2, 0)

#clip to [0,1] for valid display
img_un = torch.clamp(img_un, 0, 1) #this code is for restrict all pixel between 0 and 1 before plotting


# Plot
plt.figure(figsize=(6, 6))
plt.imshow(img_un)
plt.axis("off")
plt.title("Image after unnormalizing")

"""  Turn loaded image into dataloader's"""

from torch.utils.data import DataLoader
import os
#set batch_size
batch_size=64
num_workers = 0 # Changed num_workers to 0 to potentially resolve multiprocessing issues
train_dataloader = DataLoader(dataset=train_data,
                  batch_size=batch_size,
                  num_workers=num_workers, # Corrected num_worker to num_workers
                  shuffle=True,
                  pin_memory=True)
test_dataloader = DataLoader(dataset=test_data,
                  batch_size=batch_size,
                  num_workers=num_workers, # Corrected num_worker to num_workers
                  shuffle=False)

num_workers

train_dataloader, test_dataloader

"""Create resnet model class

*   List item
*   List item


"""

import torch.nn as nn
import torchvision.models as models
from torchvision.models import ResNet50_Weights

def create_resnet_model(num_classes: int):
   #load a pre-trained resnet50 model
    model = models.resnet50(weights=ResNet50_Weights.DEFAULT)
    #freeze the base model parameters
    for param in model.parameters():
        param.requires_grad = False

      #replace the final fully conencted layer
    model.fc = nn.Linear(in_features=model.fc.in_features, out_features=num_classes)
    return model

#create instance of tinyvgg
torch.manual_seed(42)
# Define device
device = "cuda" if torch.cuda.is_available() else "cpu"
# insatantial the model
model = create_resnet_model(num_classes=len(train_data.classes)).to(device)
print(model)

"""Try a forward pass on a single image"""

#Get a single image batch
image_batch, label_batch = next(iter(train_dataloader))
image_batch.shape, label_batch.shape
#batch size will now be 1, you can change the batch size if you like
print(f"image shape: {image_batch.shape} -> [batch_size, color_channels, height, width]")
print(f"label shape: {label_batch.shape}")

32 * 3 * 128 * 128

#try a forward pass
model(image_batch.to(device))

"""Try intall torchinfo. import it if available"""

try:
  import torchinfo
except:
  !pip install torchinfo
  import torchinfo
from torchinfo import summary
summary(model, input_size=[32, 3, 224, 224])

"""Create train and test loop function

train_step() - take in a model and dataloader and trains the model on the dataloader


test_step() - take in a model and dataloader and evaluate the model on the dataloader
"""

#create train_step()
def train_step(model: torch.nn.Module,
        dataloader: torch.utils.data.DataLoader,
        loss_fn: torch.nn.Module,
        optimizer: torch.optim.Optimizer,
        device=device):
  #put the model in train mode
  model.train()
  #setup train loss and train accuracy values
  train_loss, train_acc = 0,0 # Initialize train_loss and train_acc
  #loop through data loader data batches
  for batch, (X,y) in enumerate(dataloader):
    #send data to the target device
    X,y = X.to(device), y.to(device)
    #1.Forward pass
    y_pred = model(X) #output model logits
    #2.calculate the loss
    loss = loss_fn(y_pred, y)
    train_loss += loss.item()
    #3.optimizer zero grad
    optimizer.zero_grad()
    #4.Loss backward
    loss.backward()
    #5.optimizer step
    optimizer.step()
    #calculate accuracy metric
    print(f"Shape of y_pred before softmax and argmax: {y_pred.shape}") # Debug print
    y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)
    train_acc += (y_pred_class == y).sum().item()/len(y_pred)

  #adjust metrics to get average loss and accuracy per batch
  train_loss = train_loss / len(dataloader)
  train_acc = train_acc / len(dataloader)
  return train_loss, train_acc

"""Create a test step"""

def test_step(model: torch.nn.Module,
       dataloader: torch.utils.data.DataLoader,
        loss_fn: torch.nn.Module,
        device=device):
  #put model in eval mode
  model.eval()
  #setup test loss and test accuracy value
  test_loss, test_acc = 0,0 # Initialize test_loss and test_acc
  #turn on inference mode
  with torch.inference_mode():
    #loop through dataloader batches
    for batch, (X,y) in enumerate(dataloader):
      #send data to the target device
      X,y = X.to(device), y.to(device)
      #forward pass
      test_pred_logits = model(X)
      #calculate the loss
      loss = loss_fn(test_pred_logits, y)
      test_loss += loss.item()
      #calculate the accuracy
      print(f"Shape of test_pred_logits before argmax: {test_pred_logits.shape}") # Debug print
      test_pred_labels = test_pred_logits.argmax(dim=1)
      test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))

  #adjust metrics to get average loss and accuracy per batch
  test_loss = test_loss / len(dataloader)
  test_acc = test_acc / len(dataloader)
  return test_loss, test_acc

"""Create a train() function to combaine train_step() and test_step()

"""

from re import L
from tqdm.auto import tqdm
#create resnet50 with output classes = number of train class
model = create_resnet_model(num_classes=len(train_data.classes)).to(device)
#define optimizer
optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)
#create a train function that make in various model parameter + optimizer + dataloaders + loss function
def train(model: torch.nn.Module,
      train_dataloader: torch.utils.data.DataLoader,
      test_dataloader: torch.utils.data.DataLoader,
      optimizer: torch.optim.Optimizer,
      loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),
      epochs: int = 10,
      device = device):
  #create empty results dictionary
  results = {"train_loss":[],
        "train_acc":[],
        "test_loss":[],
        "test_acc":[]}
  #loop through training and testing steps for a number of epochs
  #we don't need optimizer
  for epoch in tqdm(range(epochs)): # Renamed loop variable to epoch
    train_loss, train_acc = train_step(model=model,
                      dataloader=train_dataloader,
                      loss_fn=loss_fn,
                      optimizer=optimizer,
                     device=device)
    test_loss, test_acc = test_step(model=model,
                     dataloader=test_dataloader,
                     loss_fn=loss_fn,
                     device=device)

    #print out what's happening
    print(f"Epoch: {epoch} | train_loss: {train_loss: 4f} | test loss: {test_loss: 4f} | test acc: {test_acc: 4f}")

    #update result dictionary
    results["train_loss"].append(train_loss)
    results["train_acc"].append(train_acc) # Corrected typo from resulte to results
    results["test_loss"].append(test_loss)
    results["test_acc"].append(test_acc)

  #return the filled results as the end of the epochs
  return results

len(train_dataloader)

import torch
print(torch.cuda.is_available())
!nvidia-smi

"""Train and evaluate model 0"""

#set random seeds
import torch
torch.manual_seed(42)
torch.cuda.manual_seed(42)
#set num of epochs
num_epochs = 10
#recreate an instance of tinyvgg
model_resnet = create_resnet_model(num_classes=len(train_data.classes)).to(device)
#setup loss function and optimizer
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(params=model_resnet.parameters(), lr=0.001)
#start the time
from timeit import default_timer as timer
start_time = timer()
#train model_0
resnet_result = train(model=model_resnet,
            train_dataloader = train_dataloader, # Changed to train_dataloader
            test_dataloader = test_dataloader, # Changed to test_dataloader
            optimizer=optimizer,
            loss_fn=loss_fn,
            epochs=num_epochs)

#end the timer and print out how long it took
end_time = timer()
print(f"Total training time: {end_time - start_time:.3f} seconds") # Fixed f-string syntax



# Create an instance of TinyVGG with the correct output shape
torch.manual_seed(42)
model_0 = create_resnet_model(num_classes=len(train_data.classes)).to(device)
model_0

"""Plot model_0"""

#get the model_0_results keys
resnet_result.keys()

from typing import Dict, List
import matplotlib.pyplot as plt

def plot_loss_curve(results: Dict[str, List[float]]):
  """plots training curve of a results dictionary."""
  #get the loss value of results dictionary(train and test)
  loss = results['train_loss']
  test_loss = results['test_loss']
  #get the accuracy value of the results dictionary(train and test)
  accuracy = results['train_acc']
  test_accuracy = results['test_acc']
  #figure out how many epochs there were
  epochs = range(len(results['train_loss']))
  #setup a plot
  plt.figure(figsize=(15,7))
  #plot the loss
  plt.subplot(1, 2, 1)
  plt.plot(epochs, loss, label='train_loss')
  plt.plot(epochs, test_loss, label='test_loss')
  plt.title('Loss')
  plt.xlabel('Epochs')
  plt.legend()
  #plot the accuracy
  plt.subplot(1, 2, 2)
  plt.plot(epochs, accuracy, label='train_accuracy')
  plt.plot(epochs, test_accuracy, label='test_accuracy')
  plt.title('Accuracy')
  plt.xlabel('Epochs')
  plt.legend()

plot_loss_curve(resnet_result)

model_0.state_dict()

"""save model"""

import torch.nn as nn
import torchvision.models as models
from torchvision.models import ResNet50_Weights
import torch
from torch.utils.data import DataLoader
from torchvision import models,transforms

def create_resnet_model(num_classes: int):
   #load a pre-trained resnet50 model for transfer learning
    model = models.resnet50(weights=ResNet50_Weights.DEFAULT)
    #freeze the base model parameters
    for param in model.parameters():
        param.requires_grad = False

      #replace the final fully conencted layer
    model.fc = nn.Linear(in_features=model.fc.in_features,out_features=num_classes)

    for param in model.layer4.parameters():
        param.requires_grad = True

    return model

    num_classes = 37
    model = create_resnet_model(num_classes)

"""Apply Pruning

Why pruning?

because most of the weights in a nn can be removed with limited to no effect on the loss(pruning)

why is it useful?

Faster inference time:

Resnet 50 real time example on a 4 core cpu

4 years ago, a few hundread milliseconds per image

today, tens of millisecond per image

pruned, sub ten millisecond


reduction in size:

vgg 16 is around 500 mb

prohibitive for most edge deployment

with pruning, 11.3mb
"""

from torch.nn.utils import prune
from torchvision import models
import torch.nn as nn
import torch.optim as optim

num_classes = 37
model = create_resnet_model(num_classes)
#Prune 20% of the weights in the first convolutional layer
prune.random_unstructured(model.conv1, name="weight", amount=0.2)

#prune 20% of the weights in the fully connected layer
prune.random_unstructured(model.fc, name="weight", amount=0.2)

#prune 20% of the weights in the layer4
prune.random_unstructured(model.layer4[0].conv1, name="weight", amount=0.2)

#set up the optimizer and training parameter
optimizer = optim.Adam(model.parameters(), lr=0.001)

"""Quantization"""

import torch
import torch.nn.utils.prune as prune

# Assume you have a pruned/quantized model after training
def remove_pruning(model):
    for module in model.modules():
        if hasattr(module, "weight_orig") and hasattr(module, "weight_mask"):
            # Restore the actual weight by combining original weight and mask
            module.weight = torch.nn.Parameter(module.weight_orig * module.weight_mask)
            # Remove the original and mask parameters
            del module._parameters["weight_orig"]
            del module._buffers["weight_mask"]
    return model

# Remove pruning wrappers
model = remove_pruning(model)

# Save a clean state_dict
torch.save(model.state_dict(), "clean_model.pth")
print("Clean model saved successfully")

from google.colab import drive
import torch
drive.mount('/content/drive') # Mount drive if not already mounted

# Save the model
torch.save(quantized_model.state_dict(), '/content/drive/MyDrive/my_model.pth')
print("Already save it to drive")

"""Load model"""

# 1. Redefine the same model structure
import torch.nn as nn
import torchvision.models as models
from torchvision.models import ResNet50_Weights
import torch
from torch.utils.data import DataLoader
from torchvision import models,transforms

def create_resnet_model(num_classes: int):
   #load a pre-trained resnet50 model for transfer learning
    model = models.resnet50(weights=ResNet50_Weights.DEFAULT)
    #freeze the base model parameters
    for param in model.parameters():
        param.requires_grad = False

      #replace the final fully conencted layer
    model.fc = nn.Linear(in_features=model.fc.in_features,out_features=num_classes)

    for param in model.layer4.parameters():
        param.requires_grad = True

    return model

    num_classes = 37
    model = create_resnet_model(num_classes)

# 2. Recreate the model
device = "cuda" if torch.cuda.is_available() else "cpu"
model = create_resnet_model(num_classes).to(device)

# 3. Load the weights
model.load_state_dict(torch.load("quantized_model.pth", map_location=device),strict=False)
model.eval()
print("âœ… Model loaded successfully!")

print(quantized_model)

